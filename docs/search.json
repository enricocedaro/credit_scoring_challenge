[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "üìÑ Introdu√ß√£o: Credit Scoring Challenge",
    "section": "",
    "text": "Este relat√≥rio t√©cnico tem como objetivo prim√°rio a constru√ß√£o de um modelo de Credit Scoring.\n\n\n\nA base de dados utilizada comp√µe-se de 10.738 registros e 81 vari√°veis mascaradas, sendo que o ‚Äúid‚Äù √© a chave √∫nica da tabela, ‚Äúsafra‚Äù √© o m√™s ano de concess√£o do cr√©dito, ‚Äúy‚Äù √© a vari√°vel target e as demais s√£o vari√°veis preditoras mascaradas.\n\n\n\nO projeto abrange o fluxo completo de Data Science, focado em entregar um modelo de Credit Scoring est√°vel e aplic√°vel ao neg√≥cio.\nA metodologia √© estruturada em quatro pilares:\n\n\nExploratory Data Analysis (EDA): Explora√ß√£o dos dados.\nFeature Engineering: Limpeza de vari√°veis, separa√ß√£o, imputa√ß√£o etc.\nModel Training: Compara√ß√£o de algoritmos (priorizando estabilidade e interpretabilidade) para identificar o melhor preditor.\nTunning: Aplica√ß√£o de met√≥dos para encontrar os melhores par√¢metros do modelo.\nFinal Model: An√°lise final de m√©tricas (AUC, Gini, KS).",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html#objetivo-central",
    "href": "index.html#objetivo-central",
    "title": "üìÑ Introdu√ß√£o: Credit Scoring Challenge",
    "section": "",
    "text": "Este relat√≥rio t√©cnico tem como objetivo prim√°rio a constru√ß√£o de um modelo de Credit Scoring.",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html#estrutura-do-desafio-e-dados",
    "href": "index.html#estrutura-do-desafio-e-dados",
    "title": "üìÑ Introdu√ß√£o: Credit Scoring Challenge",
    "section": "",
    "text": "A base de dados utilizada comp√µe-se de 10.738 registros e 81 vari√°veis mascaradas, sendo que o ‚Äúid‚Äù √© a chave √∫nica da tabela, ‚Äúsafra‚Äù √© o m√™s ano de concess√£o do cr√©dito, ‚Äúy‚Äù √© a vari√°vel target e as demais s√£o vari√°veis preditoras mascaradas.",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html#escopo-e-metodologia",
    "href": "index.html#escopo-e-metodologia",
    "title": "üìÑ Introdu√ß√£o: Credit Scoring Challenge",
    "section": "",
    "text": "O projeto abrange o fluxo completo de Data Science, focado em entregar um modelo de Credit Scoring est√°vel e aplic√°vel ao neg√≥cio.\nA metodologia √© estruturada em quatro pilares:\n\n\nExploratory Data Analysis (EDA): Explora√ß√£o dos dados.\nFeature Engineering: Limpeza de vari√°veis, separa√ß√£o, imputa√ß√£o etc.\nModel Training: Compara√ß√£o de algoritmos (priorizando estabilidade e interpretabilidade) para identificar o melhor preditor.\nTunning: Aplica√ß√£o de met√≥dos para encontrar os melhores par√¢metros do modelo.\nFinal Model: An√°lise final de m√©tricas (AUC, Gini, KS).",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "abas/04_tunning.html",
    "href": "abas/04_tunning.html",
    "title": "4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final",
    "section": "",
    "text": "Nesta etapa, o modelo de Regress√£o Log√≠stica escolhido na Etapa 3 √© otimizado usando pesquisa de hiperpar√¢metros e, em seguida, validado no conjunto de Teste Out-of-Time (OOT).\n\n\n\nO modelo foi otimizado utilizando o RandomizedSearchCV, buscando maximizar o KS Score, uma m√©trica cr√≠tica para separa√ß√£o de risco\nO processo de tunning focou na regulariza√ß√£o do modelo para evitar overfitting e garantir a robustez.\nMelhores Par√¢metros Encontrados:\n\n\n\nPar√¢metro\nValor Otimizado\n\n\n\n\nn_estimators\n800\n\n\nlearning_rate\n0.01\n\n\nsubsample\n0.7\n\n\nreg_alpha / reg_lambda\n0.0 / 0.0\n\n\n\n\n\n\n\nO modelo otimizado foi treinado na base completa de Treino e avaliado no conjunto de Teste OOT, confirmando seu potencial m√°ximo.\n\n\n\nM√©trica\nValor\n\n\n\n\nKS\n0.313688\n\n\nAUC\n0.708333\n\n\nGini\n0.416665\n\n\n\nAp√≥s o tunning, o LightGBM alcan√ßou o melhor desempenho absoluto no Teste OOT, com AUC de 0.708 e Gini de 0.417. Este resultado supera o modelo de Regress√£o Log√≠stica (AUC 0.701) e confirma o LightGBM como o modelo mais preditivo para o modelo.",
    "crumbs": [
      "04. Tunning"
    ]
  },
  {
    "objectID": "abas/04_tunning.html#estrat√©gia-de-otimiza√ß√£o",
    "href": "abas/04_tunning.html#estrat√©gia-de-otimiza√ß√£o",
    "title": "4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final",
    "section": "",
    "text": "O modelo foi otimizado utilizando o RandomizedSearchCV, buscando maximizar o KS Score, uma m√©trica cr√≠tica para separa√ß√£o de risco\nO processo de tunning focou na regulariza√ß√£o do modelo para evitar overfitting e garantir a robustez.\nMelhores Par√¢metros Encontrados:\n\n\n\nPar√¢metro\nValor Otimizado\n\n\n\n\nn_estimators\n800\n\n\nlearning_rate\n0.01\n\n\nsubsample\n0.7\n\n\nreg_alpha / reg_lambda\n0.0 / 0.0",
    "crumbs": [
      "04. Tunning"
    ]
  },
  {
    "objectID": "abas/04_tunning.html#performance-final-do-lightgbm-teste-oot",
    "href": "abas/04_tunning.html#performance-final-do-lightgbm-teste-oot",
    "title": "4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final",
    "section": "",
    "text": "O modelo otimizado foi treinado na base completa de Treino e avaliado no conjunto de Teste OOT, confirmando seu potencial m√°ximo.\n\n\n\nM√©trica\nValor\n\n\n\n\nKS\n0.313688\n\n\nAUC\n0.708333\n\n\nGini\n0.416665\n\n\n\nAp√≥s o tunning, o LightGBM alcan√ßou o melhor desempenho absoluto no Teste OOT, com AUC de 0.708 e Gini de 0.417. Este resultado supera o modelo de Regress√£o Log√≠stica (AUC 0.701) e confirma o LightGBM como o modelo mais preditivo para o modelo.",
    "crumbs": [
      "04. Tunning"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html",
    "href": "abas/02_feature_engineering.html",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "Esta se√ß√£o detalha as t√©cnicas de pr√©-processamento e sele√ß√£o aplicadas para garantir um conjunto de features robusto e de alta qualidade para a modelagem. O objetivo √© remover ru√≠dos, redund√¢ncias e vari√°veis inst√°veis.\n\n\n\nO primeiro passo foi remover vari√°veis que n√£o agregam valor preditivo ou que apresentam alta incerteza devido √† falta de dados.\nCrit√©rio de Descarte adotado para Missing Values: Vari√°veis com mais de 60% de valores ausentes foram descartadas.\n\n\n\n\n\n\n\n\n\nTipo de Vari√°vel Removida\nContagem\nExemplo\nJustificativa\n\n\n\n\nAlto Missing (&gt;60%)\n19\nVAR_62, VAR_70, etc.\nAlta incerteza e baixa confiabilidade estat√≠stica.\n\n\nConstante\n0\nN/A\nN√£o h√° vari√°veis com valor √∫nico.\n\n\nID-Like\n1\nID_COL\nVari√°veis √∫nicas por linha n√£o carregam informa√ß√£o generaliz√°vel.\n\n\n\n19 features foram removidas, resultando em 62 features restantes para a an√°lise (81 originais - 19 removidas).\n\n\n\n\nA classifica√ß√£o correta das vari√°veis √© uma etapa essencial para garantir que o pr√©-processamento subsequente seja aplicado de forma adequada (ex: One-Hot Encoding para categ√≥ricas, Scaling para num√©ricas).\n\n\nDada a natureza mascarada das features, a distin√ß√£o entre vari√°veis cont√≠nuas e discretas foi feita utilizando a Cardinalidade (n√∫mero de valores √∫nicos) como crit√©rio principal.\nThreshold Definido: Foi estabelecido um threshold de 25 valores √∫nicos.\n\nVari√°veis Categ√≥ricas (CAT_VARS): Features com at√© 25 valores √∫nicos foram classificadas como categ√≥ricas, pois representam um conjunto discreto e gerenci√°vel de classes.\nVari√°veis Num√©ricas (NUM_VARS): Features com mais de 25 valores √∫nicos foram classificadas como num√©ricas, indicando uma distribui√ß√£o de dados cont√≠nua ou de alta vari√¢ncia.\n\n\n\n\nAp√≥s a classifica√ß√£o, as features em CAT_VARS foram explicitamente convertidas para o tipo object (tipo Python para string ou categoria). Esta convers√£o √© necess√°ria para garantir que os pipelines de pr√©-processamento (como OneHotEncoder) as tratem corretamente, independentemente de seu tipo original.\n\n\n\n\n\nVari√°veis com baix√≠ssima varia√ß√£o (proximidade de valor constante) n√£o distinguem bem os clientes e s√£o removidas.\nBaixa Vari√¢ncia: Foi definido um threshold de 0.001. Apenas 1 feature foi removida por ter vari√¢ncia muito pr√≥xima de zero.\nA base n√£o possui colunas duplicadas.\n\n\n\n\nA multicolinearidade entre features num√©ricas √© prejudicial para a modelagem, pois torna os coeficientes do modelo inst√°veis e dif√≠ceis de interpretar.\nCrit√©rio de Descarte: Manter apenas uma vari√°vel de cada par que apresentava correla√ß√£o absoluta superior a 0.9 na base de Treino.\n\n\n\nvar1\nvar2\ncorr\n\n\n\n\nVAR_19\nVAR_22\n0.975977\n\n\nVAR_10\nVAR_69\n0.975103\n\n\nVAR_24\nVAR_58\n0.974130\n\n\nVAR_39\nVAR_45\n0.972208\n\n\nVAR_14\nVAR_26\n0.954847\n\n\n\n5 features foram removidas devido √† alta correla√ß√£o. O conjunto de dados final possui 56 features candidatas (61 restantes - 5 removidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#filtragem-inicial-missing-constantes-e-ids",
    "href": "abas/02_feature_engineering.html#filtragem-inicial-missing-constantes-e-ids",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "O primeiro passo foi remover vari√°veis que n√£o agregam valor preditivo ou que apresentam alta incerteza devido √† falta de dados.\nCrit√©rio de Descarte adotado para Missing Values: Vari√°veis com mais de 60% de valores ausentes foram descartadas.\n\n\n\n\n\n\n\n\n\nTipo de Vari√°vel Removida\nContagem\nExemplo\nJustificativa\n\n\n\n\nAlto Missing (&gt;60%)\n19\nVAR_62, VAR_70, etc.\nAlta incerteza e baixa confiabilidade estat√≠stica.\n\n\nConstante\n0\nN/A\nN√£o h√° vari√°veis com valor √∫nico.\n\n\nID-Like\n1\nID_COL\nVari√°veis √∫nicas por linha n√£o carregam informa√ß√£o generaliz√°vel.\n\n\n\n19 features foram removidas, resultando em 62 features restantes para a an√°lise (81 originais - 19 removidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#classifica√ß√£o-de-vari√°veis-categ√≥ricas-vs.-num√©ricas",
    "href": "abas/02_feature_engineering.html#classifica√ß√£o-de-vari√°veis-categ√≥ricas-vs.-num√©ricas",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "A classifica√ß√£o correta das vari√°veis √© uma etapa essencial para garantir que o pr√©-processamento subsequente seja aplicado de forma adequada (ex: One-Hot Encoding para categ√≥ricas, Scaling para num√©ricas).\n\n\nDada a natureza mascarada das features, a distin√ß√£o entre vari√°veis cont√≠nuas e discretas foi feita utilizando a Cardinalidade (n√∫mero de valores √∫nicos) como crit√©rio principal.\nThreshold Definido: Foi estabelecido um threshold de 25 valores √∫nicos.\n\nVari√°veis Categ√≥ricas (CAT_VARS): Features com at√© 25 valores √∫nicos foram classificadas como categ√≥ricas, pois representam um conjunto discreto e gerenci√°vel de classes.\nVari√°veis Num√©ricas (NUM_VARS): Features com mais de 25 valores √∫nicos foram classificadas como num√©ricas, indicando uma distribui√ß√£o de dados cont√≠nua ou de alta vari√¢ncia.\n\n\n\n\nAp√≥s a classifica√ß√£o, as features em CAT_VARS foram explicitamente convertidas para o tipo object (tipo Python para string ou categoria). Esta convers√£o √© necess√°ria para garantir que os pipelines de pr√©-processamento (como OneHotEncoder) as tratem corretamente, independentemente de seu tipo original.",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#filtragem-por-baixa-vari√¢ncia-e-duplicatas",
    "href": "abas/02_feature_engineering.html#filtragem-por-baixa-vari√¢ncia-e-duplicatas",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "Vari√°veis com baix√≠ssima varia√ß√£o (proximidade de valor constante) n√£o distinguem bem os clientes e s√£o removidas.\nBaixa Vari√¢ncia: Foi definido um threshold de 0.001. Apenas 1 feature foi removida por ter vari√¢ncia muito pr√≥xima de zero.\nA base n√£o possui colunas duplicadas.",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#tratamento-de-multicolinearidade-alta-correla√ß√£o",
    "href": "abas/02_feature_engineering.html#tratamento-de-multicolinearidade-alta-correla√ß√£o",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "A multicolinearidade entre features num√©ricas √© prejudicial para a modelagem, pois torna os coeficientes do modelo inst√°veis e dif√≠ceis de interpretar.\nCrit√©rio de Descarte: Manter apenas uma vari√°vel de cada par que apresentava correla√ß√£o absoluta superior a 0.9 na base de Treino.\n\n\n\nvar1\nvar2\ncorr\n\n\n\n\nVAR_19\nVAR_22\n0.975977\n\n\nVAR_10\nVAR_69\n0.975103\n\n\nVAR_24\nVAR_58\n0.974130\n\n\nVAR_39\nVAR_45\n0.972208\n\n\nVAR_14\nVAR_26\n0.954847\n\n\n\n5 features foram removidas devido √† alta correla√ß√£o. O conjunto de dados final possui 56 features candidatas (61 restantes - 5 removidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html",
    "href": "abas/01_exploratory_data_analysis.html",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "Este cap√≠tulo apresenta a explora√ß√£o da base de dados, a defini√ß√£o da separa√ß√£o de teste e treino e as an√°lises iniciais de qualidade e distribui√ß√£o de risco.\n\n\n\nA base de dados bruta cont√©m 10.738 observa√ß√µes e 81 colunas (incluindo id, safra e features).\nDefini√ß√£o da Vari√°vel Alvo (y) - n√£o tem nulos\n\ny = 1 (Mau Pagador): Inadimpl√™ncia (default)\ny = 0 (Bom Pagador): N√£o-inadimpl√™ncia\n\nA Taxa de Inadimpl√™ncia Global da amostra √© de 29,13%.\n\n\n\nClasse\nContagem Absoluta\nPropor√ß√£o\n\n\n\n\n0 (Bom Pagador)\n7.610\n70,87%\n\n\n1 (Mau Pagador)\n3.128\n29,13%\n\n\n\n\n\n\n\nA an√°lise do risco ao longo do tempo (safra) √© crucial em cr√©dito. A base abrange 12 meses, de 01/2014 a 12/2014.\nO gr√°fico abaixo mostra a varia√ß√£o da taxa de inadimpl√™ncia (m√©dia de y) em cada safra.\n\nA taxa de inadimpl√™ncia demonstra uma tend√™ncia de aumento nas safras finais (11/2014 e 12/2014), atingindo o pico de 35,24% na √∫ltima safra. Este pico √© significativamente maior do que a m√©dia da amostra (29,13%), sugerindo uma poss√≠vel instabilidade temporal ou uma mudan√ßa no perfil de risco dos clientes mais recentes.\n\n\n\n\nPara garantir que o modelo de Credit Scoring seja robusto ao longo do tempo, √© essencial monitorar as features mais preditivas e verificar se suas distribui√ß√µes se mant√™m est√°veis ao longo das safras.\nGr√°fico de estabilidade da VAR_1:\n\n\n\n\n\nA qualidade dos dados foi avaliada, com foco na presen√ßa de valores ausentes (Missing Values).\nTotal de Features Analisadas: 78 Amostra Total: 10.738 linhas\n\nConclus√£o e Pr√≥xima Etapa: H√° uma grande quantidade de vari√°veis com uma alta percentagem de valores ausentes (mais de 50%). Na fase 02_feature_engineering.ipynb, ser√° necess√°rio definir um limite de corte para descarte de vari√°veis.\n\n\n\n\nSepara√ß√£o temporal entre treino e teste:\nEmbora a base permita uma divis√£o aleat√≥ria entre treino e teste, optei por utilizar a vari√°vel safra para construir um cen√°rio mais pr√≥ximo do uso real do modelo em produ√ß√£o.\nAl√©m disso foi considerado a inadimpl√™ncia das safras, com as √∫ltimas sendo ‚Äúpiores‚Äù.\nTreino: safra &lt;= 2024-09 (28% de default m√©dio)\nTeste out-of-time: safra &gt; 2024-09 (32% de default m√©dio)",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#defini√ß√£o-do-target-e-distribui√ß√£o-da-amostra",
    "href": "abas/01_exploratory_data_analysis.html#defini√ß√£o-do-target-e-distribui√ß√£o-da-amostra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A base de dados bruta cont√©m 10.738 observa√ß√µes e 81 colunas (incluindo id, safra e features).\nDefini√ß√£o da Vari√°vel Alvo (y) - n√£o tem nulos\n\ny = 1 (Mau Pagador): Inadimpl√™ncia (default)\ny = 0 (Bom Pagador): N√£o-inadimpl√™ncia\n\nA Taxa de Inadimpl√™ncia Global da amostra √© de 29,13%.\n\n\n\nClasse\nContagem Absoluta\nPropor√ß√£o\n\n\n\n\n0 (Bom Pagador)\n7.610\n70,87%\n\n\n1 (Mau Pagador)\n3.128\n29,13%",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#estabilidade-temporal-da-inadimpl√™ncia-an√°lise-por-safra",
    "href": "abas/01_exploratory_data_analysis.html#estabilidade-temporal-da-inadimpl√™ncia-an√°lise-por-safra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A an√°lise do risco ao longo do tempo (safra) √© crucial em cr√©dito. A base abrange 12 meses, de 01/2014 a 12/2014.\nO gr√°fico abaixo mostra a varia√ß√£o da taxa de inadimpl√™ncia (m√©dia de y) em cada safra.\n\nA taxa de inadimpl√™ncia demonstra uma tend√™ncia de aumento nas safras finais (11/2014 e 12/2014), atingindo o pico de 35,24% na √∫ltima safra. Este pico √© significativamente maior do que a m√©dia da amostra (29,13%), sugerindo uma poss√≠vel instabilidade temporal ou uma mudan√ßa no perfil de risco dos clientes mais recentes.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#estabilidade-das-vari√°veis-por-safra",
    "href": "abas/01_exploratory_data_analysis.html#estabilidade-das-vari√°veis-por-safra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "Para garantir que o modelo de Credit Scoring seja robusto ao longo do tempo, √© essencial monitorar as features mais preditivas e verificar se suas distribui√ß√µes se mant√™m est√°veis ao longo das safras.\nGr√°fico de estabilidade da VAR_1:",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#qualidade-e-sa√∫de-dos-dados-valores-ausentes",
    "href": "abas/01_exploratory_data_analysis.html#qualidade-e-sa√∫de-dos-dados-valores-ausentes",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A qualidade dos dados foi avaliada, com foco na presen√ßa de valores ausentes (Missing Values).\nTotal de Features Analisadas: 78 Amostra Total: 10.738 linhas\n\nConclus√£o e Pr√≥xima Etapa: H√° uma grande quantidade de vari√°veis com uma alta percentagem de valores ausentes (mais de 50%). Na fase 02_feature_engineering.ipynb, ser√° necess√°rio definir um limite de corte para descarte de vari√°veis.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#sele√ß√£o-da-base-treino-e-teste",
    "href": "abas/01_exploratory_data_analysis.html#sele√ß√£o-da-base-treino-e-teste",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "Separa√ß√£o temporal entre treino e teste:\nEmbora a base permita uma divis√£o aleat√≥ria entre treino e teste, optei por utilizar a vari√°vel safra para construir um cen√°rio mais pr√≥ximo do uso real do modelo em produ√ß√£o.\nAl√©m disso foi considerado a inadimpl√™ncia das safras, com as √∫ltimas sendo ‚Äúpiores‚Äù.\nTreino: safra &lt;= 2024-09 (28% de default m√©dio)\nTeste out-of-time: safra &gt; 2024-09 (32% de default m√©dio)",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/03_model_training.html",
    "href": "abas/03_model_training.html",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Esta se√ß√£o detalha o pr√©-processamento final das features, a sele√ß√£o de vari√°veis baseada em import√¢ncia e a avalia√ß√£o comparativa de diferentes algoritmos de Machine Learning.\n\n\n\nTodas as 56 features restantes foram submetidas a um Pipeline de pr√©-processamento padr√£o:\n\nImputa√ß√£o de Missing Values: Utiliza√ß√£o da mediana para preencher valores ausentes nas vari√°veis num√©ricas e moda nas vari√°veis categ√≥ricas.\nPadroniza√ß√£o (StandardScaler e One-Hot Encoding): Aplica√ß√£o do StandardScaler nas vari√°veis n√∫mericas e One-Hot Encoding para as vari√°veis categ√≥ricas.\n\n\n\n\n\nPara refinar o modelo e reduzir a complexidade e o risco de overfitting, foi utilizado um modelo Random Forest para ranquear as features por import√¢ncia (Feature Importance).\nObjetivo: Selecionar as Top K=20 vari√°veis que mais contribuem para a separa√ß√£o entre Bons e Maus Pagadores.\n\nO dataset para o treinamento final foi reduzido de 56 para 20 features, focado nas vari√°veis com maior poder preditivo.\n\n\n\n\nQuatro modelos foram comparados utilizando Cross-Validation Estratificada (5 splits) no conjunto de Treino (X_train_sel).\n\n\nAs m√©tricas priorizadas foram:\n\nAUC (Area Under the Curve): Probabilidade de o modelo ranquear um par aleat√≥rio (Mau Pagador, Bom Pagador) na ordem correta.\nGini Coefficient: Mede a separa√ß√£o das distribui√ß√µes.\nKS (Kolmogorov-Smirnov): Mede a separa√ß√£o m√°xima entre as distribui√ß√µes acumuladas de Bons e Maus Pagadores.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo\nKS M√©dio\nKS Desvio\nAUC M√©dio\nAUC Desvio\nGini M√©dio\nGini Desvio\n\n\n\n\nLightGBM\n0.447\n0.022\n0.796\n0.011\n0.593\n0.022\n\n\nLogistic Regression\n0.424\n0.013\n0.786\n0.011\n0.571\n0.022\n\n\nRandom Forest\n0.433\n0.019\n0.785\n0.009\n0.569\n0.017\n\n\nXGBoost\n0.424\n0.034\n0.783\n0.015\n0.566\n0.029\n\n\n\nConclus√£o do Treino: O LightGBM demonstrou o melhor desempenho preditivo bruto, estabelecendo o teto da performance com o maior AUC (0.796) e Gini (0.593). A Regress√£o Log√≠stica e o Random Forest se mostraram altamente competitivos, ficando a menos de 1 ponto percentual de dist√¢ncia no AUC.\n\n\n\n\n\nA performance de cada modelo foi avaliada no conjunto de Teste (Out-of-Time - OOT), que representa o ambiente de risco futuro. A estabilidade √© medida pela capacidade do modelo de reter seu poder preditivo em dados futuros (OOT).\n\n\n\nModelo\nKS\nAUC\nGini\n\n\n\n\nLightGBM\n0.306\n0.704\n0.407\n\n\nLogistic Regression\n0.294\n0.701\n0.402\n\n\nRandom Forest\n0.265\n0.685\n0.369\n\n\nXGBoost\n0.255\n0.668\n0.337\n\n\n\nConclus√£o: Devido a sua performance superior, o LightGBM √© o modelo escolhido para o Credit Scoring final.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#pr√©-processamento-e-pipelines",
    "href": "abas/03_model_training.html#pr√©-processamento-e-pipelines",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Todas as 56 features restantes foram submetidas a um Pipeline de pr√©-processamento padr√£o:\n\nImputa√ß√£o de Missing Values: Utiliza√ß√£o da mediana para preencher valores ausentes nas vari√°veis num√©ricas e moda nas vari√°veis categ√≥ricas.\nPadroniza√ß√£o (StandardScaler e One-Hot Encoding): Aplica√ß√£o do StandardScaler nas vari√°veis n√∫mericas e One-Hot Encoding para as vari√°veis categ√≥ricas.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#sele√ß√£o-final-de-vari√°veis-random-forest",
    "href": "abas/03_model_training.html#sele√ß√£o-final-de-vari√°veis-random-forest",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Para refinar o modelo e reduzir a complexidade e o risco de overfitting, foi utilizado um modelo Random Forest para ranquear as features por import√¢ncia (Feature Importance).\nObjetivo: Selecionar as Top K=20 vari√°veis que mais contribuem para a separa√ß√£o entre Bons e Maus Pagadores.\n\nO dataset para o treinamento final foi reduzido de 56 para 20 features, focado nas vari√°veis com maior poder preditivo.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#avalia√ß√£o-comparativa-de-modelos-cross-validation",
    "href": "abas/03_model_training.html#avalia√ß√£o-comparativa-de-modelos-cross-validation",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Quatro modelos foram comparados utilizando Cross-Validation Estratificada (5 splits) no conjunto de Treino (X_train_sel).\n\n\nAs m√©tricas priorizadas foram:\n\nAUC (Area Under the Curve): Probabilidade de o modelo ranquear um par aleat√≥rio (Mau Pagador, Bom Pagador) na ordem correta.\nGini Coefficient: Mede a separa√ß√£o das distribui√ß√µes.\nKS (Kolmogorov-Smirnov): Mede a separa√ß√£o m√°xima entre as distribui√ß√µes acumuladas de Bons e Maus Pagadores.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo\nKS M√©dio\nKS Desvio\nAUC M√©dio\nAUC Desvio\nGini M√©dio\nGini Desvio\n\n\n\n\nLightGBM\n0.447\n0.022\n0.796\n0.011\n0.593\n0.022\n\n\nLogistic Regression\n0.424\n0.013\n0.786\n0.011\n0.571\n0.022\n\n\nRandom Forest\n0.433\n0.019\n0.785\n0.009\n0.569\n0.017\n\n\nXGBoost\n0.424\n0.034\n0.783\n0.015\n0.566\n0.029\n\n\n\nConclus√£o do Treino: O LightGBM demonstrou o melhor desempenho preditivo bruto, estabelecendo o teto da performance com o maior AUC (0.796) e Gini (0.593). A Regress√£o Log√≠stica e o Random Forest se mostraram altamente competitivos, ficando a menos de 1 ponto percentual de dist√¢ncia no AUC.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#valida√ß√£o-final-teste-oot",
    "href": "abas/03_model_training.html#valida√ß√£o-final-teste-oot",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "A performance de cada modelo foi avaliada no conjunto de Teste (Out-of-Time - OOT), que representa o ambiente de risco futuro. A estabilidade √© medida pela capacidade do modelo de reter seu poder preditivo em dados futuros (OOT).\n\n\n\nModelo\nKS\nAUC\nGini\n\n\n\n\nLightGBM\n0.306\n0.704\n0.407\n\n\nLogistic Regression\n0.294\n0.701\n0.402\n\n\nRandom Forest\n0.265\n0.685\n0.369\n\n\nXGBoost\n0.255\n0.668\n0.337\n\n\n\nConclus√£o: Devido a sua performance superior, o LightGBM √© o modelo escolhido para o Credit Scoring final.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/05_final_model.html",
    "href": "abas/05_final_model.html",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "Esta fase consolida a performance do modelo LightGBM tunado, analisando em profundidade a separa√ß√£o de risco (ROC/KS), a distribui√ß√£o do score (Taxa de Evento por Quantil) e a calibra√ß√£o da probabilidade de default no conjunto de Teste OOT.\n\n\n\nO modelo final (LightGBM) foi avaliado em ambos os conjuntos.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase\nAUC\nKS\nGini\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nTeste (OOT)\n0.708\n0.314\n0.417\n0.694\n0.589\n0.159\n0.250\n\n\n\n\n\n\n\n\n\nA Curva ROC no Teste OOT confirma o poder de ranqueamento, com um AUC de 0.708.\n\n\n\n\nO KS Score de 0.314 indica que a separa√ß√£o m√°xima entre a distribui√ß√£o acumulada de Bons e Maus Pagadores √© de 31.4%, um resultado satisfat√≥rio.\n\n\n\n\n\n\nA an√°lise por quantis (decis) √© a tradu√ß√£o mais direta do poder de ranqueamento para o neg√≥cio, mostrando a concentra√ß√£o de risco.\nO gr√°fico de Taxa de Evento compara a frequ√™ncia observada de default por faixas de score (quantis) no Treino e no Teste OOT.\n\nO gr√°fico mostra que o modelo est√° conseguindo organizar bem a carteira em faixas de risco. A medida que vamos do quantil 1 para o quantil 10, tanto no treino quanto na valida√ß√£o a taxa de inadimpl√™ncia aumenta, indicando que scores piores de fato concentram clientes mais problem√°ticos. As curvas de treino e valida√ß√£o n√£o s√£o id√™nticas, mas o padr√£o crescente se mant√©m.\n\n\n\n\nKS por Safra\nA an√°lise do KS m√™s a m√™s (por safra) √© a verifica√ß√£o mais rigorosa da estabilidade preditiva ao longo do tempo.\n\nO KS no Teste OOT (safras 10/2014 a 12/2014) mostra uma queda de performance na √∫ltima safra (12/2014). Isso pode ser um sinal de mudan√ßa no mercado ou mudan√ßa de pol√≠tica de cr√©dito.\nCurva de Calibra√ß√£o\nA curva de calibra√ß√£o verifica se a probabilidade prevista (P(Default)) corresponde √† frequ√™ncia real de default observada.\n\nO modelo ranqueia bem e tem uma calibra√ß√£o aceit√°vel nas faixas centrais, mas tende a subestimar a inadimpl√™ncia tanto nos clientes de risco baixo (especialmente em valida√ß√£o) quanto, principalmente, nos de maior risco em treino. Faz sentido aplicar uma etapa extra de recalibra√ß√£o (Platt, isot√¥nica ou ajuste por faixas de score).\n\n\n\nNa an√°lise de estabilidade das vari√°veis entre o per√≠odo de treino e o per√≠odo de teste, utilizamos o Population Stability Index (PSI), calculado a partir da distribui√ß√£o das features no conjunto de desenvolvimento (treino) em compara√ß√£o com o conjunto de teste. Seguindo a pr√°tica de mercado, interpretamos os valores de PSI da seguinte forma:\nPSI &lt; 0,10 ‚Üí vari√°vel est√°vel;\n0,10 ‚â§ PSI ‚â§ 0,25 ‚Üí mudan√ßa moderada;\nPSI &gt; 0,25 ‚Üí mudan√ßa severa na distribui√ß√£o.\nA maior parte das vari√°veis do modelo apresentou PSI baixo ou moderado, indicando comportamento relativamente est√°vel entre os per√≠odos. No entanto, duas vari√°veis chamaram aten√ß√£o: VAR_53 e VAR_54, com PSI acima de 0,6, respectivamente, claramente acima do limiar de mudan√ßa severa.\nElas s√£o reconhecidamente inst√°veis, sendo recomend√°vel retirar elas do treinamento.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#m√©tricas-de-desempenho-finais",
    "href": "abas/05_final_model.html#m√©tricas-de-desempenho-finais",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "O modelo final (LightGBM) foi avaliado em ambos os conjuntos.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase\nAUC\nKS\nGini\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nTeste (OOT)\n0.708\n0.314\n0.417\n0.694\n0.589\n0.159\n0.250",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#curvas-de-ranqueamento",
    "href": "abas/05_final_model.html#curvas-de-ranqueamento",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "A Curva ROC no Teste OOT confirma o poder de ranqueamento, com um AUC de 0.708.\n\n\n\n\nO KS Score de 0.314 indica que a separa√ß√£o m√°xima entre a distribui√ß√£o acumulada de Bons e Maus Pagadores √© de 31.4%, um resultado satisfat√≥rio.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#taxa-de-evento-por-quantil-lift-analysis",
    "href": "abas/05_final_model.html#taxa-de-evento-por-quantil-lift-analysis",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "A an√°lise por quantis (decis) √© a tradu√ß√£o mais direta do poder de ranqueamento para o neg√≥cio, mostrando a concentra√ß√£o de risco.\nO gr√°fico de Taxa de Evento compara a frequ√™ncia observada de default por faixas de score (quantis) no Treino e no Teste OOT.\n\nO gr√°fico mostra que o modelo est√° conseguindo organizar bem a carteira em faixas de risco. A medida que vamos do quantil 1 para o quantil 10, tanto no treino quanto na valida√ß√£o a taxa de inadimpl√™ncia aumenta, indicando que scores piores de fato concentram clientes mais problem√°ticos. As curvas de treino e valida√ß√£o n√£o s√£o id√™nticas, mas o padr√£o crescente se mant√©m.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#estabilidade-temporal-do-ks-e-calibra√ß√£o",
    "href": "abas/05_final_model.html#estabilidade-temporal-do-ks-e-calibra√ß√£o",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "KS por Safra\nA an√°lise do KS m√™s a m√™s (por safra) √© a verifica√ß√£o mais rigorosa da estabilidade preditiva ao longo do tempo.\n\nO KS no Teste OOT (safras 10/2014 a 12/2014) mostra uma queda de performance na √∫ltima safra (12/2014). Isso pode ser um sinal de mudan√ßa no mercado ou mudan√ßa de pol√≠tica de cr√©dito.\nCurva de Calibra√ß√£o\nA curva de calibra√ß√£o verifica se a probabilidade prevista (P(Default)) corresponde √† frequ√™ncia real de default observada.\n\nO modelo ranqueia bem e tem uma calibra√ß√£o aceit√°vel nas faixas centrais, mas tende a subestimar a inadimpl√™ncia tanto nos clientes de risco baixo (especialmente em valida√ß√£o) quanto, principalmente, nos de maior risco em treino. Faz sentido aplicar uma etapa extra de recalibra√ß√£o (Platt, isot√¥nica ou ajuste por faixas de score).",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#psi",
    "href": "abas/05_final_model.html#psi",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "Na an√°lise de estabilidade das vari√°veis entre o per√≠odo de treino e o per√≠odo de teste, utilizamos o Population Stability Index (PSI), calculado a partir da distribui√ß√£o das features no conjunto de desenvolvimento (treino) em compara√ß√£o com o conjunto de teste. Seguindo a pr√°tica de mercado, interpretamos os valores de PSI da seguinte forma:\nPSI &lt; 0,10 ‚Üí vari√°vel est√°vel;\n0,10 ‚â§ PSI ‚â§ 0,25 ‚Üí mudan√ßa moderada;\nPSI &gt; 0,25 ‚Üí mudan√ßa severa na distribui√ß√£o.\nA maior parte das vari√°veis do modelo apresentou PSI baixo ou moderado, indicando comportamento relativamente est√°vel entre os per√≠odos. No entanto, duas vari√°veis chamaram aten√ß√£o: VAR_53 e VAR_54, com PSI acima de 0,6, respectivamente, claramente acima do limiar de mudan√ßa severa.\nElas s√£o reconhecidamente inst√°veis, sendo recomend√°vel retirar elas do treinamento.",
    "crumbs": [
      "05. Final Model"
    ]
  }
]