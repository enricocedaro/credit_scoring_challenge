{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7576cc9f",
   "metadata": {},
   "source": [
    "# 1.Imports, configs e constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e73d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "TARGET_COL = \"y\"\n",
    "ID_COL = \"id\"\n",
    "TIME_COL = \"safra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1279bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT ROOT: c:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Descobre o diretório raiz do projeto (onde fica a pasta src/)\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"src\").exists():\n",
    "    # se estiver rodando de dentro de notebooks/, sobe um nível\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "sys.path.append(str(ROOT))\n",
    "print(\"PROJECT ROOT:\", ROOT)\n",
    "\n",
    "from src.utils import (\n",
    "    ks_score,\n",
    "    performance_metrics,\n",
    "    construct_metrics_table,\n",
    "    ks_safe,\n",
    "    psi_for_feature,\n",
    "    psi_for_dataframe,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0a3d4",
   "metadata": {},
   "source": [
    "# 2. Ler bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a13b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\data\\processed\\train.csv')\n",
    "df_test  = pd.read_csv(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\data\\processed\\test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f4cf9",
   "metadata": {},
   "source": [
    "# 3. Missing, Constant e Id-Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4177d913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High missing: 19\n",
      "Constant: 0\n",
      "ID-like: 1\n"
     ]
    }
   ],
   "source": [
    "total_rows_train = df_train.shape[0]\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"dtype\": df_train.dtypes,\n",
    "    \"n_missing\": df_train.isna().sum(),\n",
    "    \"pct_missing\": df_train.isna().mean() * 100,\n",
    "    \"n_unique\": df_train.nunique()\n",
    "})\n",
    "\n",
    "summary[\"is_constant\"] = summary[\"n_unique\"] == 1\n",
    "summary[\"is_id_like\"]  = summary[\"n_unique\"] == total_rows_train\n",
    "\n",
    "missing_threshold = 60.0  # acima desse percentual descartar\n",
    "\n",
    "high_missing_cols = summary[summary[\"pct_missing\"] > missing_threshold].index.tolist() \n",
    "constant_cols     = summary[summary[\"is_constant\"]].index.tolist() # coluna com registros iguais\n",
    "id_like_cols      = summary[summary[\"is_id_like\"]].index.tolist() # coluna com muitos registros únicos\n",
    "\n",
    "print(\"High missing:\", len(high_missing_cols))\n",
    "print(\"Constant:\", len(constant_cols))\n",
    "print(\"ID-like:\", len(id_like_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fc088e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,\n",
       " ['VAR_12',\n",
       "  'VAR_16',\n",
       "  'VAR_18',\n",
       "  'VAR_21',\n",
       "  'VAR_36',\n",
       "  'VAR_41',\n",
       "  'VAR_43',\n",
       "  'VAR_47',\n",
       "  'VAR_48',\n",
       "  'VAR_49',\n",
       "  'VAR_50',\n",
       "  'VAR_55',\n",
       "  'VAR_56',\n",
       "  'VAR_61',\n",
       "  'VAR_62',\n",
       "  'VAR_63',\n",
       "  'VAR_68',\n",
       "  'VAR_70',\n",
       "  'VAR_75'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo colunas dessa etapa para dropar\n",
    "protected_cols = [TARGET_COL, ID_COL, TIME_COL]\n",
    "\n",
    "cols_to_drop_missing_constant_id = sorted(\n",
    "    set(high_missing_cols + constant_cols + id_like_cols)\n",
    "    - set(protected_cols)\n",
    ")\n",
    "\n",
    "len(cols_to_drop_missing_constant_id), cols_to_drop_missing_constant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fb64c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8211, 62), (2527, 62))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropando colunas definidas\n",
    "df_train1 = df_train.drop(columns=cols_to_drop_missing_constant_id)\n",
    "df_test1  = df_test.drop(columns=cols_to_drop_missing_constant_id)\n",
    "\n",
    "df_train1.shape, df_test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8bf7a2",
   "metadata": {},
   "source": [
    "# 4. Classificando as varíaveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ab1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_CARDINALIDADE = 25\n",
    "\n",
    "colunas_explicativas = [\n",
    "    c for c in df_train1.columns\n",
    "    if c not in TARGET_COL + ID_COL + TIME_COL\n",
    "]\n",
    "\n",
    "cardinalidade = df_train1[colunas_explicativas].nunique(dropna=True)\n",
    "\n",
    "metadados = (\n",
    "    pd.DataFrame({\n",
    "        \"FEATURE\": cardinalidade.index,\n",
    "        \"CARDINALIDADE\": cardinalidade.values,\n",
    "    })\n",
    "    .sort_values(\"CARDINALIDADE\")\n",
    ")\n",
    "\n",
    "CAT_VARS = metadados.loc[\n",
    "    metadados[\"CARDINALIDADE\"] <= THRESHOLD_CARDINALIDADE,\n",
    "    \"FEATURE\"\n",
    "].tolist()\n",
    "\n",
    "NUM_VARS = metadados.loc[\n",
    "    metadados[\"CARDINALIDADE\"] > THRESHOLD_CARDINALIDADE,\n",
    "    \"FEATURE\"\n",
    "].tolist()\n",
    "\n",
    "# 1) Converter as variáveis categóricas para tipo 'object'\n",
    "df_train1[CAT_VARS] = df_train1[CAT_VARS].astype(\"object\")\n",
    "df_test1[CAT_VARS]  = df_test1[CAT_VARS].astype(\"object\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09535aa",
   "metadata": {},
   "source": [
    "# 5. Variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e299b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44,\n",
       " ['VAR_1',\n",
       "  'VAR_5',\n",
       "  'VAR_6',\n",
       "  'VAR_7',\n",
       "  'VAR_8',\n",
       "  'VAR_9',\n",
       "  'VAR_10',\n",
       "  'VAR_11',\n",
       "  'VAR_13',\n",
       "  'VAR_14'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleciona colunas numéricas\n",
    "numeric_cols = df_train1.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Garante que não entra a target nem id/safra\n",
    "for col in [TARGET_COL, ID_COL, TIME_COL]:\n",
    "    if col in numeric_cols:\n",
    "        numeric_cols.remove(col)\n",
    "\n",
    "len(numeric_cols), numeric_cols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628d73c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.400000e+01\n",
       "mean     1.500910e+06\n",
       "std      7.123118e+06\n",
       "min      3.289287e+01\n",
       "25%      2.597023e+03\n",
       "50%      5.985683e+04\n",
       "75%      1.479520e+05\n",
       "max      4.707317e+07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variances = df_train1[numeric_cols].var()\n",
    "variances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461bce59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variances = df_train1[numeric_cols].var()\n",
    "\n",
    "low_var_threshold = 0.001  # valor padrão\n",
    "low_var_cols = variances[variances < low_var_threshold].index.tolist()\n",
    "\n",
    "len(low_var_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d40177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8211, 62), (2527, 62))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2 = df_train1.drop(columns=low_var_cols)\n",
    "df_test2  = df_test1.drop(columns=low_var_cols)\n",
    "\n",
    "df_train2.shape, df_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b122ac3",
   "metadata": {},
   "source": [
    "# 6. Colunas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19817d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categóricas em step2\n",
    "cat_cols = df_train2.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Garante que y/safra não entrem aqui\n",
    "for col in [TARGET_COL, TIME_COL]:\n",
    "    if col in cat_cols:\n",
    "        cat_cols.remove(col)\n",
    "\n",
    "len(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811dadc5",
   "metadata": {},
   "source": [
    "# 7. Muticolinearidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d52169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de correlação entre features numéricas\n",
    "num_cols = df_train2.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "for col in [TARGET_COL, ID_COL, TIME_COL]:\n",
    "    if col in num_cols:\n",
    "        num_cols.remove(col)\n",
    "\n",
    "corr_matrix = df_train2[num_cols].corr().abs()\n",
    "\n",
    "len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b6576b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>VAR_19</td>\n",
       "      <td>VAR_22</td>\n",
       "      <td>0.975977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>VAR_10</td>\n",
       "      <td>VAR_69</td>\n",
       "      <td>0.975103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>VAR_24</td>\n",
       "      <td>VAR_58</td>\n",
       "      <td>0.974130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>VAR_39</td>\n",
       "      <td>VAR_45</td>\n",
       "      <td>0.972208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>VAR_14</td>\n",
       "      <td>VAR_26</td>\n",
       "      <td>0.954847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1    var2      corr\n",
       "450  VAR_19  VAR_22  0.975977\n",
       "276  VAR_10  VAR_69  0.975103\n",
       "559  VAR_24  VAR_58  0.974130\n",
       "794  VAR_39  VAR_45  0.972208\n",
       "357  VAR_14  VAR_26  0.954847"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar pares com correlação maior que 0.9\n",
    "upper = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "corr_pairs = corr_matrix.where(upper)\n",
    "\n",
    "high_corr_pairs = (\n",
    "    corr_pairs.stack()\n",
    "              .reset_index()\n",
    "              .rename(columns={\"level_0\": \"var1\", \"level_1\": \"var2\", 0: \"corr\"})\n",
    "              .query(\"corr > 0.9\")\n",
    "              .sort_values(\"corr\", ascending=False)\n",
    ")\n",
    "\n",
    "high_corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad173a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VAR_22', 'VAR_26', 'VAR_45', 'VAR_58', 'VAR_69']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando colunas para dropar\n",
    "cols_to_drop_high_corr = sorted(set(high_corr_pairs[\"var2\"].tolist()))\n",
    "cols_to_drop_high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4663a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8211, 57), (2527, 57))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropando colunas definidas\n",
    "df_train3 = df_train2.drop(columns=cols_to_drop_high_corr)\n",
    "df_test3  = df_test2.drop(columns=cols_to_drop_high_corr)\n",
    "\n",
    "df_train3.shape, df_test3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455d018",
   "metadata": {},
   "source": [
    "# 8. PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df50c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_for_feature(train: pd.Series, test: pd.Series, n_bins: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    Calcula o PSI de uma feature contínua/categorizada, usando bins baseados no treino.\n",
    "    \"\"\"\n",
    "    # Remove NaN\n",
    "    train = train.dropna()\n",
    "    test = test.dropna()\n",
    "\n",
    "    # Definir bins com base no treino (quantis)\n",
    "    quantiles = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_edges = np.unique(np.quantile(train, quantiles))\n",
    "\n",
    "    # Se der menos de 2 edges únicos, PSI = 0 (sem variação)\n",
    "    if len(bin_edges) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    train_bins = pd.cut(train, bins=bin_edges, include_lowest=True)\n",
    "    test_bins  = pd.cut(test,  bins=bin_edges, include_lowest=True)\n",
    "\n",
    "    train_dist = train_bins.value_counts(normalize=True).sort_index()\n",
    "    test_dist  = test_bins.value_counts(normalize=True).sort_index()\n",
    "\n",
    "    # Alinha índices\n",
    "    test_dist = test_dist.reindex(train_dist.index).fillna(0.0)\n",
    "\n",
    "    # Evitar log(0)\n",
    "    epsilon = 1e-6\n",
    "    train_dist = train_dist.clip(epsilon, 1)\n",
    "    test_dist  = test_dist.clip(epsilon, 1)\n",
    "\n",
    "    psi_values = (train_dist - test_dist) * np.log(train_dist / test_dist)\n",
    "    return float(psi_values.sum())\n",
    "\n",
    "\n",
    "def psi_for_dataframe(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    n_bins: int = 10,\n",
    ") -> pd.Series:\n",
    "    psi_dict = {}\n",
    "    for col in feature_cols:\n",
    "        psi_dict[col] = psi_for_feature(df_train[col], df_test[col], n_bins=n_bins)\n",
    "    return pd.Series(psi_dict).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1640612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAR_30    0.201377\n",
       "VAR_1     0.114739\n",
       "VAR_27    0.085693\n",
       "VAR_17    0.083235\n",
       "VAR_52    0.076833\n",
       "VAR_15    0.070507\n",
       "VAR_53    0.069508\n",
       "VAR_14    0.062152\n",
       "VAR_51    0.051285\n",
       "VAR_31    0.030933\n",
       "VAR_37    0.029473\n",
       "VAR_38    0.025040\n",
       "VAR_6     0.023270\n",
       "VAR_5     0.020802\n",
       "VAR_59    0.017588\n",
       "VAR_29    0.017382\n",
       "VAR_23    0.017316\n",
       "VAR_46    0.016887\n",
       "VAR_9     0.016821\n",
       "VAR_35    0.015473\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular PSI para features numéricas\n",
    "num_cols_fe = df_train3.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in [TARGET_COL, ID_COL, TIME_COL]:\n",
    "    if col in num_cols_fe:\n",
    "        num_cols_fe.remove(col)\n",
    "\n",
    "psi_values = psi_for_dataframe(df_train3, df_test3, num_cols_fe, n_bins=10)\n",
    "psi_values.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9053",
   "metadata": {},
   "source": [
    "PSI < 0.1 → estável\n",
    "\n",
    "0.1 ≤ PSI < 0.25 → moderada mudança\n",
    "\n",
    "PSI ≥ 0.25 → forte mudança de distribuição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "184c24b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_psi_cols = psi_values[psi_values >= 0.25].index.tolist()\n",
    "medium_psi_cols = psi_values[(psi_values >= 0.1) & (psi_values < 0.25)].index.tolist()\n",
    "\n",
    "len(high_psi_cols), len(medium_psi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a61d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garantir a igualdade da base\n",
    "set(df_train3.columns) == set(df_train3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f97a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train3.to_csv(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\data\\processed\\train_fe.csv', index=False)\n",
    "df_test3.to_csv(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\data\\processed\\test_fe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
