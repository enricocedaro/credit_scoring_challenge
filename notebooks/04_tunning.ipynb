{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91c9f81",
   "metadata": {},
   "source": [
    "# 1. Imports e configs e constantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4f6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f32e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT ROOT: c:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Descobre o diretório raiz do projeto (onde fica a pasta src/)\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"src\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "sys.path.append(str(ROOT))\n",
    "print(\"PROJECT ROOT:\", ROOT)\n",
    "\n",
    "from src.utils import (\n",
    "    ks_score,\n",
    "    performance_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356da0d",
   "metadata": {},
   "source": [
    "# 2. Ler bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae62fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de treino e teste já com feature engineering\n",
    "df_train_fe = pd.read_csv(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\data\\processed\\train_fe.csv')\n",
    "df_test_fe = pd.read_csv(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\data\\processed\\test_fe.csv')\n",
    "\n",
    "# Carrega as colunas selecionadas\n",
    "selected_features = joblib.load(r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\models\\selected_features.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304423f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8211, 20), (2527, 20))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TARGET_COL = \"y\"\n",
    "X_train = df_train_fe[selected_features].copy()\n",
    "y_train = df_train_fe[TARGET_COL].copy()\n",
    "\n",
    "X_test  = df_test_fe[selected_features].copy()\n",
    "y_test  = df_test_fe[TARGET_COL].copy()\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd298b1e",
   "metadata": {},
   "source": [
    "# 3. Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8b61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer baseado no seu ks_score\n",
    "ks_scorer = make_scorer(ks_score, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf5f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_base = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    n_estimators=400,       \n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    \"num_leaves\":        [31, 63, 127],\n",
    "    \"max_depth\":         [-1, 4, 6, 8],\n",
    "    \"learning_rate\":     [0.01, 0.03, 0.05, 0.1],\n",
    "    \"n_estimators\":      [200, 400, 600, 800],\n",
    "    \"min_child_samples\": [20, 50, 100],\n",
    "    \"subsample\":         [0.7, 0.8, 0.9],    \n",
    "    \"colsample_bytree\":  [0.7, 0.8, 0.9],        \n",
    "    \"reg_alpha\":         [0.0, 0.1, 0.5],\n",
    "    \"reg_lambda\":        [0.0, 0.1, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c99a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2316, number of negative: 5895\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3631\n",
      "[LightGBM] [Info] Number of data points in the train set: 8211, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282061 -> initscore=-0.934263\n",
      "[LightGBM] [Info] Start training from score -0.934263\n",
      "Melhor KS (CV): nan\n",
      "Melhores parâmetros LightGBM:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'reg_lambda': 0.0,\n",
       " 'reg_alpha': 0.0,\n",
       " 'num_leaves': 31,\n",
       " 'n_estimators': 800,\n",
       " 'min_child_samples': 20,\n",
       " 'max_depth': -1,\n",
       " 'learning_rate': 0.01,\n",
       " 'colsample_bytree': 0.8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    estimator=lgbm_base,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,                \n",
    "    scoring=ks_scorer,         # otimizar KS\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "random_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhor KS (CV):\", random_search_lgbm.best_score_)\n",
    "print(\"Melhores parâmetros LightGBM:\")\n",
    "random_search_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8273b6",
   "metadata": {},
   "source": [
    "# 4. Teste com hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a285da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2316, number of negative: 5895\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3631\n",
      "[LightGBM] [Info] Number of data points in the train set: 8211, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282061 -> initscore=-0.934263\n",
      "[LightGBM] [Info] Start training from score -0.934263\n",
      "Desempenho LightGBM tunado - TESTE:\n",
      "  KS   = 0.313688\n",
      "  AUC  = 0.708333\n",
      "  Gini = 0.416665\n"
     ]
    }
   ],
   "source": [
    "best_lgbm = random_search_lgbm.best_estimator_\n",
    "\n",
    "# Treinar de novo\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Probabilidades no teste\n",
    "y_proba_test_lgbm = best_lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ks_t, auc_t, gini_t = performance_metrics(y_test, y_proba_test_lgbm)\n",
    "\n",
    "print(f\"Desempenho LightGBM tunado - TESTE:\")\n",
    "print(f\"  KS   = {ks_t:.6f}\")\n",
    "print(f\"  AUC  = {auc_t:.6f}\")\n",
    "print(f\"  Gini = {gini_t:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29920b5b",
   "metadata": {},
   "source": [
    "# 5. Salvar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b791540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Enrico\\\\OneDrive\\\\Documentos\\\\Python\\\\credit_scoring_challenge\\\\models\\\\final_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_lgbm, r'C:\\Users\\Enrico\\OneDrive\\Documentos\\Python\\credit_scoring_challenge\\models\\final_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
